
<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8"/>
    <meta name="viewport"
          content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css"
          rel="stylesheet"
	  integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3"
	  crossorigin="anonymous">

    <link rel="stylesheet"
    href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.4.0/build/styles/default.min.css">
    <script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.4.0/build/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>

    <title>Scene Representation Transformer</title>
    <style>
      .paper-title {
        margin-top: 2em;
        margin-bottom: 2em;
      }
      .long-name {
        font-size: 1.5em;
      }
      .authors-list .name {
        font-size: 0.7em;
        /*font-weight: bold;*/
      }
      .authors-list .affiliation {
        font-size: 1.0em;
      }
      .paper-link a {
        font-size: 1.5em;
      }
      .short-videos video {
        padding: 1em;
      }
      .content-block {
        padding-left: 2em;
        padding-right: 2em;
        padding-bottom: 2em;
      }
      .overview-video {
        background-color: rgb(240,240,240);
      }
      .overview-video .video-col {
        margin-left: 2em;
        margin-right: 2em;
      }
      .video-row {
        margin-top: 1em;
        margin-bottom: 1em;
      }
      .geometric-consistency {
        background-color: rgb(240,240,240);
      }
      .dataset {
        background-color: rgb(240,240,240);
      }
      .citation {
        /* background-color: rgb(240,240,240); */
      }
      .citation .description {
        font-family: "Courier",monospace;
        white-space: pre-wrap;
        text-align: left;
        font-size: 0.7em;
      }
      .additional-links {
        background-color: #f4f4f4;
      }
      .textcommumn {
        text-align: center;
      }
      @media (min-width: 1000px) {
	      .container {
		      max-width: 900px;
	      }
      }
      .teaser {
	      width: 100%;
	      max-width: 520px;
      }
    </style>
  </head>

  <body>
    <div class="container">
      <div class="paper-title">
        <!-- title -->
        <div class="row">
          <div class="col">
		  <h1 class="name text-center">Scene Representation Transformer</h1>
          </div>
        </div>
        <div class="row">
          <div class="col">
            <p class="long-name text-center">
		Geometry-Free Novel View Synthesis Through Set-Latent Scene Representations
            </p>
          </div>
        </div>

      <!-- Authors -->
      <div class="authors-list">
        <div class="row gx-1">
          <div class="col">
            <p class="name text-center">
            <a href="http://msajjadi.com/"
	       target="_blank" >Mehdi S. M.</br>Sajjadi</a> <a href="mailto:srt@msajjadi.com,tutmann+srt@google.com">üìß</a>
            </p>
          </div>
          <div class="col">
            <p class="name text-center">
            <a href="https://scholar.google.com/citations?user=XZYOFQcAAAAJ"
	       target="_blank" >Henning</br>Meyer</a> <a href="mailto:tutmann+srt@google.com,srt@msajjadi.com">üìß</a>
            </p>
          </div>
          <div class="col">
            <p class="name text-center">
            <a href="https://github.com/Conchylicultor"
		    target="_blank" >Etienne</br>Pot</a>
            </p>
          </div>
          <div class="col">
            <p class="name text-center">
            <a href="https://scholar.google.de/citations?user=9f4oVfMAAAAJ"
		    target="_blank" >Urs</br>Bergmann</a>
            </p>
          </div>
          <div class="col">
            <p class="name text-center">
            <a
            <a href="https://scholar.google.com/citations?user=OcownLgAAAAJ"
		    target="_blank" >Klaus</br>Greff</a>
            </p>
          </div>
          <div class="col">
            <p class="name text-center">
            <a href="https://scholar.google.com/citations?user=g98QcZUAAAAJ"
		    target="_blank" >Noha</br>Radwan</a>
            </p>
          </div>
          <div class="col">
            <p class="name text-center">
            <a href="https://scholar.google.com/citations?user=mOOsGrQAAAAJ"
		    target="_blank" >Suhani</br>Vora</a>
            </p>
          </div>
          <div class="col">
            <p class="name text-center">
            <a href="https://lucic.ai/"
		    target="_blank" >Mario</br>Luƒçiƒá</a>
            </p>
          </div>
          <div class="col">
            <p class="name text-center">
            <a href="https://www.stronglyconvex.com/about.html"
	       target="_blank" >Daniel</br>Duckworth</a>
            </p>
          </div>
          <div class="col">
            <p class="name text-center">
            <a href="https://scholar.google.de/citations?user=FXNJRDoAAAAJ"
    	       target="_blank" >Alexey</br>Dosovitskiy</a>
            </p>
          </div>
          <div class="col">
            <p class="name text-center">
            <a href="http://jakob.uszkoreit.net/"
	       target="_blank" >Jakob</br>Uszkoreit</a>
            </p>
          </div>
          <div class="col">
            <p class="name text-center">
            <a href="https://research.google/people/ThomasFunkhouser/"
		    target="_blank" >Thomas</br>Funkhouser</a>
            </p>
          </div>
          <div class="col">
            <p class="name text-center">
            <a href="https://taiya.github.io"
	       target="_blank" >Andrea</br>Tagliasacchi</a>
            </p>
          </div>
        </div>
        <div class="row">
          <div class="col">
		  <p class="text-center">
	    <img src="data/google-research-logo.svg" alt="Google Research" width="150em"/>
		  </p>
          </div>
        </div>
        <div class="row">
          <div class="col">
		  <p class="text-center">
	            CVPR 2022
		  </p>
          </div>
        </div>
      </div>
    </div>

      <!-- Links -->
      <div class="paper-link">
        <div class="row">
          <div class="col">
            <p class="text-center">
	      <a href="https://arxiv.org/abs/2111.13152">[Paper]</a>
		    &nbsp;&nbsp;&nbsp;&nbsp;
	      <a href="#dataset">[Dataset]</a>
		    &nbsp;&nbsp;&nbsp;&nbsp;
	      <a href="#code">[Code]</a>
            </p>
          </div>
        </div>
      </div>

      <!-- Teaser -->
      <div class="content-block">
        <div class="row">
          <div class="col text-center">
	    <img src="data/teaser.svg" alt="Model Overview" class="teaser"/>
          </div>
		  <p class="text">
SRT takes few <strong>posed or unposed</strong> images of <strong>novel real-world scenes</strong> as input and produces a <strong>set-latent scene representation</strong> that is decoded to <strong>3D videos & semantics</strong>, entirely in <strong>real-time</strong>.
The model is <strong>fully geometry-free</strong>, instead powered by <strong>Transformers</strong> and <strong>attention</strong> mechanisms.
		  </p>
        </div>
      </div>


      <!-- Supplementary videos -->
      <div class="content-block additional-links">
        <div class="row">
          <div class="col">
            <p class="title">
              <h3>Examples</h3>
            </p>
          </div>
        </div>
        <div class="row textcommumn">
          <div class="col">
            <a href="data/streetview.html">
              <img src="data/streetview/image1.gif">
              <p>
                Street View
              </p>
            </a>
          </div>
          <div class="col">
            <a href="data/multi_shapenet.html">
              <img src="data/home/msn.gif">
              <p>
                MultiShapeNet (MSN)
              </p>
            </a>
          </div>
          <div class="col">
            <a href="data/nmr.html">
              <img src="data/home/shapenet.gif">
              <p>
                ShapeNet (NMR)
              </p>
            </a>
          </div>
        </div>
      </div>

      <!-- Abstract -->
      <div class="abstract content-block">
        <div class="row">
          <div class="col">
            <p class="title">
              <h3>Abstract</h3>
            </p>
          </div>
        </div>
        <div class="row">
          <div class="col">
		  <p class="text">
A classical problem in computer vision is to infer a 3D scene representation from few images that can be used to render novel views at interactive rates.
Previous work focuses on reconstructing pre-defined 3D representations, e.g.textured meshes, or implicit representations, e.g. radiance fields, and often requires input images with precise camera poses and long processing times for each novel scene.
		  </p>
		  <p class="text">
In this work, we propose the Scene Representation Transformer (SRT), a method which processes posed or unposed RGB images of a new area, infers a ‚Äúset-latent scene representation‚Äù, and synthesises novel views, all in a single feed-forward pass.
To calculate the scene representation, we propose a generalization of the Vision Transformer to sets of images, enabling global information integration, and hence 3D reasoning.
An efficient decoder transformer parameterizes the light field by attending into the scene representation to render novel views. Learning is supervised end-to-end by minimizing a novel-view reconstruction error.
		  </p>
		  <p class="text">
We show that this method outperforms recent baselines in terms of PSNR and speed on synthetic datasets, including a new dataset created for the paper.
Further, we demonstrate that SRT scales to support interactive visualization and semantic segmentation of real-world outdoor environments using Street View imagery.
		  </p>
          </div>
        </div>
      </div>

      <!-- Dataset -->
      <div class="content-block dataset", id="dataset">
        <div class="row">
          <div class="col">
            <p class="title">
              <h3>Dataset</h3>
            </p>
          </div>
        </div>
        <div class="row">
          <div class="col">
            <p class="text">
            Our MultiShapeNet (MSN) dataset is publicly available.
            </p>
            <ul>
              <li>Location: <a href="https://console.cloud.google.com/storage/browser/kubric-public/tfds/multi_shapenet_frames/">gs://kubric-public/tfds/multi_shapenet_frames/</a></li>
              <li>Format: tf-record</li>
              <li>Train split: 1.047.815 scenes</li>
              <li>Validation split: 104.657 scenes</li>
              <li>Test split: 10.000 scenes</li>
              <li>Dataset size: 344.77 GiB</li>
            </ul>
            <p>
              You can read the data directly from <code>data_dir='gs://kubric-public/tfds'</code>. However, for best 
              performance, it's recommended to copy the data locally with
              <a href="https://cloud.google.com/storage/docs/gsutil_install">gsutil</a>:
            </p>
            <pre><code class="language-bash">
DATA_DIR=~/tensorflow_datasets/
mkdir $DATA_DIR
gsutil -m cp -r gs://kubric-public/tfds/multi_shapenet_frames/ $DATA_DIR
</code></pre>
            <p>
              Once downloaded, you can plug the data directly into your model using <a href="https://github.com/google-research/sunds">SunDs</a>:
            </p>
            <pre><code class="language-python">
import sunds

builder = sunds.builder('multi_shapenet')
print(builder.frame_builder.info)  # Print structure of the dataset

ds = builder.as_dataset(
    split='train', 
    task=sunds.task.Nerf(yield_mode='stacked'),
)
for ex in ds.as_numpy_iterator():  # Convert TF -> numpy
    # Each example is a scene containing 10 images
    ray_origins = ex['ray_origins']  # f32[10 128 128 3]
    ray_directions = ex['ray_directions']  # f32[10 128 128 3]
    color_images = ex['color_images']  # ui8[10 128 128 3]
</code></pre>
            <code class="python">
            </code>
            <p>
              Inspect the dataset in <a href="https://colab.research.google.com/github/srt-paper/srt-paper.github.io/blob/main/multi_shapenet.ipynb">our interactive Colab</a>.</b>
            </p>
          </div>
        </div>
      </div>

      <!-- Code -->
      <div class="content-block code", id="code">
        <div class="row">
          <div class="col">
            <p class="title">
              <h3>Code</h3>
            </p>
          </div>
        </div>
        <div class="row">
          <div class="col">
            <p class="text">
            There exists an <b>independent third-party</b> implementation of SRT at <a href="https://github.com/stelzner/srt">https://github.com/stelzner/srt</a>.
            While it appears to nearly match our results, please note that <b>we have not vetted this implementation yet</b>.
            </p>
        </div>
      </div>


  <!-- Citation -->
      <div class="content-block citation">
        <div class="row">
          <div class="col">
            <p class="title">
              <h3>Citation</h3>
            </p>
          </div>
        </div>
        <div class="row">
          <div class="col">
            <p class="description">
@article{srt22,
  title={{Scene Representation Transformer: Geometry-Free Novel View Synthesis Through Set-Latent Scene Representations}},
  author={Mehdi S. M. Sajjadi and Henning Meyer and Etienne Pot and Urs Bergmann and Klaus Greff and Noha Radwan and Suhani Vora and Mario Lucic and Daniel Duckworth and Alexey Dosovitskiy and Jakob Uszkoreit and Thomas Funkhouser and Andrea Tagliasacchi},
  journal={{CVPR}},
  year={2022},
  url={https://srt-paper.github.io/},
}
            </p>
          </div>
        </div>
      </div>

      <!-- Links -->
      <!-- No Links to display currently.
      <div class="content-block additional-links">
        <div class="row">
          <div class="col">
            <p class="title">
              <h3>Additional links</h3>
            </p>
          </div>
        </div>
        <div class="row">
          <div class="col">
            <p class="description">
	    fixme
            </p>
          </div>
        </div>
      </div>
      -->
    </div>

    <!-- Bootstrap bits -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"
	    integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p"
    	    crossorigin="anonymous"></script>
  </body>
</html>

